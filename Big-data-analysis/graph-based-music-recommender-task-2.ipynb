{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph based Music Recommender. Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task description\n",
    "Data description (DataFrames in parquet format)\n",
    "Location - /data/sample264\n",
    "\n",
    "Fields: trackId, userId, timestamp, artistId\n",
    "\n",
    "trackId - id of the track\n",
    "userId - id of the user\n",
    "artistId - id of the artist\n",
    "timestamp - timestamp of the moment the user starts listening to a track\n",
    "Location - /data/meta\n",
    "\n",
    "Fields: type, Name, Artist, Id\n",
    "\n",
    "Type could be “track” or “artist”\n",
    "Name is the title of the track if the type == “track” and the name of the musician or group if the type == “artist”.\n",
    "Artist states for the creator of the track in case the type == “track” and for the name of the musician or group in case the type == “artist”.\n",
    "Id - id of the item\n",
    "Task\n",
    "Build the edges of the type “user-track”. Take the amount of times the track was listened by the user as the weight of the edge from the user's vertex to the track’s vertex. For each user take top-1000 and normalize them.\n",
    "\n",
    "Sort the resulting Data Frame in descending order by the column norm_count, take top 40 rows, select only the columns “id1”, “id2”, sort them in ascending order this time first by “id1”, then by “id2” and print the columns “id1”, “id2” of the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.1.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.12 (default, Nov 19 2016 06:48:10)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "\n",
    "execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.enableHiveSupport().master(\"local [2]\").getOrCreate()\n",
    "\n",
    "data = sparkSession.read.parquet(\"/data/sample264\")\n",
    "meta = sparkSession.read.parquet(\"/data/meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window1 = Window.partitionBy('userId').orderBy(col('count').desc())\n",
    "window2 = Window.partitionBy('userId')\n",
    "\n",
    "userToTrack = data.groupBy(col(\"userId\"), col(\"trackId\")) \\\n",
    "                  .count() \\\n",
    "                  .withColumn(\"rank\", rank().over(window1)) \\\n",
    "                  .filter(col(\"rank\") <= 1000) \\\n",
    "                  .withColumn('sum_count', sum(col('count')).over(window2)) \\\n",
    "                  .withColumn('norm_count', col('count') / col('sum_count') * 0.5) \\\n",
    "                  .orderBy(desc(\"norm_count\"), asc(\"userId\"), asc(\"trackId\")) \\\n",
    "                  .limit(40) \\\n",
    "                  .select(col(\"userId\"), col(\"trackId\")) \\\n",
    "                  .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 965774\n",
      "116 867268\n",
      "128 852564\n",
      "131 880170\n",
      "195 946408\n",
      "215 860111\n",
      "235 897176\n",
      "300 857973\n",
      "321 915545\n",
      "328 943482\n",
      "333 818202\n",
      "346 864911\n",
      "356 961308\n",
      "428 943572\n",
      "431 902497\n",
      "445 831381\n",
      "488 841340\n",
      "542 815388\n",
      "617 946395\n",
      "649 901672\n",
      "658 937522\n",
      "662 881433\n",
      "698 935934\n",
      "708 952432\n",
      "746 879259\n",
      "747 879259\n",
      "776 946408\n",
      "784 806468\n",
      "806 866581\n",
      "811 948017\n",
      "837 799685\n",
      "901 871513\n",
      "923 879322\n",
      "934 940714\n",
      "957 945183\n",
      "989 878364\n",
      "999 967768\n",
      "1006 962774\n",
      "1049 849484\n",
      "1057 920458\n"
     ]
    }
   ],
   "source": [
    "for val in userToTrack:\n",
    "    print \"%s %s\" % val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
